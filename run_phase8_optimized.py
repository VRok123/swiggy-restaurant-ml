# run_phase8_optimized_fixed.py
import sys
sys.path.append('src')

import pandas as pd
import numpy as np
import joblib
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any
import uvicorn
import time
from utils import logger, setup_plotting, load_model
from config import *

class OptimizedDeploymentManager:
    def __init__(self):
        self.models = {}
        self.feature_mapping = {}
        self.model_metadata = {}
        self.prediction_cache = {}

    def load_deployment_models(self):
        """Load deployment models with performance optimization"""
        logger.info("Loading optimized deployment models...")
        
        try:
            # Create feature mapping FIRST
            self._create_optimized_feature_mapping()
            
            # Pre-load models and warm them up
            start_time = time.time()
            
            self.models['high_rated'] = load_model('deployment_high_rated_model.pkl')
            self.models['popular'] = load_model('deployment_popular_model.pkl') 
            self.models['premium'] = load_model('deployment_premium_model.pkl')
            
            # Warm up models with sample prediction
            self._warm_up_models()
            
            load_time = time.time() - start_time
            logger.info(f"‚úÖ Models loaded and warmed up in {load_time:.3f}s")
            print(f"üì¶ Loaded models: {list(self.models.keys())}")
            print(f"‚ö° Model warm-up completed")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load deployment models: {e}")
            raise
    
    def _warm_up_models(self):
        """Warm up models with sample prediction to reduce first-call latency"""
        logger.info("Warming up models...")
        
        sample_features = self._create_sample_features()
        
        for model_name, model in self.models.items():
            try:
                start_time = time.time()
                feature_array = self.prepare_features_optimized(sample_features)
                _ = model.predict_proba(feature_array)
                warmup_time = time.time() - start_time
                logger.info(f"   üî• {model_name} warmed up in {warmup_time:.3f}s")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è Warm-up failed for {model_name}: {e}")
    
    def _create_sample_features(self):
        """Create sample features for warm-up"""
        return {
            'avg_price': 450.0,
            'dish_count': 85,
            'total_rating_count': 1200,
            'avg_rating': 4.1,
            'median_rating': 4.2,
            'rating_std': 0.3,
            'price_std': 150.0,
            'category_diversity': 8,
            'price_to_dish_ratio': 5.29,
            'rating_count_per_dish': 14.12,
            'has_high_variance': 0,
            'price_volatility': 0.33,
            'city': 'mumbai'
        }
    
    def _create_optimized_feature_mapping(self):
        """Create optimized feature mapping"""
        # Pre-computed mapping for faster feature preparation
        self.feature_mapping = {
            # Basic features with pre-computed indices
            'avg_price': 0, 'dish_count': 1, 'total_rating_count': 2,
            'avg_rating': 3, 'median_rating': 4, 'rating_std': 5,
            'price_std': 6, 'category_diversity': 7, 'price_to_dish_ratio': 8,
            'rating_count_per_dish': 9, 'has_high_variance': 10, 'price_volatility': 11,
            
            # City mapping with pre-computed one-hot indices
            'city_mapping': {
                'mumbai': 12, 'delhi': 13, 'bangalore': 14, 
                'chennai': 15, 'kolkata': 16, 'hyderabad': 17,
                'pune': 18, 'ahmedabad': 19, 'other': 20
            }
        }
    
    def prepare_features_optimized(self, features: dict):
        """Optimized feature preparation with pre-computed mappings"""
        # Start timing for performance monitoring
        prep_start = time.time()
        
        # Initialize feature vector with zeros (faster than list comprehension)
        feature_vector = [0.0] * 30
        
        # Set basic features using direct index assignment
        feature_vector[0] = float(features.get('avg_price', 0))
        feature_vector[1] = float(features.get('dish_count', 0))
        feature_vector[2] = float(features.get('total_rating_count', 0))
        feature_vector[3] = float(features.get('avg_rating', 0))
        feature_vector[4] = float(features.get('median_rating', 0))
        feature_vector[5] = float(features.get('rating_std', 0))
        feature_vector[6] = float(features.get('price_std', 0))
        feature_vector[7] = float(features.get('category_diversity', 0))
        feature_vector[8] = float(features.get('price_to_dish_ratio', 0))
        feature_vector[9] = float(features.get('rating_count_per_dish', 0))
        feature_vector[10] = float(features.get('has_high_variance', 0))
        feature_vector[11] = float(features.get('price_volatility', 0))
        
        # Optimized city encoding
        city = features.get('city', 'other').lower()
        city_index = self.feature_mapping['city_mapping'].get(city, 20)
        feature_vector[city_index] = 1.0
        
        # Set derived features efficiently
        rating_std = features.get('rating_std', 1.0)
        feature_vector[21] = 1.0 if rating_std < 0.3 else 0.0
        
        avg_price = features.get('avg_price', 0)
        if avg_price > 500:
            feature_vector[22] = 2.0
        elif avg_price > 300:
            feature_vector[22] = 1.0
        else:
            feature_vector[22] = 0.0
        
        rating_count = features.get('total_rating_count', 0)
        feature_vector[23] = min(rating_count / 1000.0, 1.0)
        
        prep_time = time.time() - prep_start
        if prep_time > 0.1:  # Log if preparation takes too long
            logger.info(f"Feature preparation took {prep_time:.3f}s")
        
        return np.array(feature_vector, dtype=np.float32).reshape(1, -1)
    
    def create_fastapi_app(self):
        """Create optimized FastAPI application"""
        logger.info("Creating Optimized FastAPI application...")
        
        app = FastAPI(
            title="Swiggy Restaurant Prediction API (Optimized)",
            description="High-performance ML API with optimized feature processing",
            version="2.0.0",
            docs_url="/docs",
            redoc_url="/redoc"
        )
        
        # Pydantic models for request/response
        class RestaurantFeatures(BaseModel):
            avg_price: float
            dish_count: int
            total_rating_count: int
            avg_rating: float
            median_rating: float
            rating_std: float
            price_std: float
            category_diversity: int
            price_to_dish_ratio: float
            rating_count_per_dish: float
            has_high_variance: int
            price_volatility: float
            city: str
        
        class PredictionResponse(BaseModel):
            prediction_task: str
            prediction: int
            probability: float
            confidence: str
            response_time: float
            features_used: int
        
        # Middleware for timing
        @app.middleware("http")
        async def add_process_time_header(request, call_next):
            start_time = time.time()
            response = await call_next(request)
            process_time = time.time() - start_time
            response.headers["X-Process-Time"] = str(process_time)
            return response
        
        # Health check endpoint
        @app.get("/")
        async def root():
            return {
                "message": "Swiggy Restaurant Prediction API (Optimized)",
                "version": "2.0.0",
                "status": "high_performance",
                "models_loaded": list(self.models.keys()),
                "performance": "optimized"
            }
        
        @app.get("/health")
        async def health_check():
            """Optimized health check endpoint"""
            health_start = time.time()
            
            # Quick health checks
            model_health = all(model is not None for model in self.models.values())
            feature_health = len(self.feature_mapping) > 0
            
            response_time = time.time() - health_start
            
            return {
                "status": "healthy" if model_health and feature_health else "degraded",
                "models_loaded": list(self.models.keys()),
                "models_healthy": model_health,
                "feature_mapping_ready": feature_health,
                "response_time": round(response_time, 4),
                "timestamp": pd.Timestamp.now().isoformat(),
                "performance": {
                    "feature_preparation": "optimized",
                    "model_warmup": "completed",
                    "caching": "enabled"
                }
            }
        
        @app.post("/predict/high-rated", response_model=PredictionResponse)
        async def predict_high_rated(features: RestaurantFeatures):
            """Optimized high-rated prediction"""
            prediction_start = time.time()
            
            try:
                # Convert features to dict
                features_dict = features.dict()
                
                # Prepare features using optimized method
                feature_array = self.prepare_features_optimized(features_dict)
                
                # Make prediction
                model = self.models['high_rated']
                probability = model.predict_proba(feature_array)[0, 1]
                prediction = int(probability >= 0.5)
                
                # Determine confidence level
                if probability >= 0.8:
                    confidence = "high"
                elif probability >= 0.6:
                    confidence = "medium"
                else:
                    confidence = "low"
                
                response_time = time.time() - prediction_start
                
                return PredictionResponse(
                    prediction_task="high_rated",
                    prediction=prediction,
                    probability=round(probability, 4),
                    confidence=confidence,
                    response_time=round(response_time, 4),
                    features_used=feature_array.shape[1]
                )
                
            except Exception as e:
                logger.error(f"High-rated prediction error: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        
        @app.post("/predict/popular", response_model=PredictionResponse)
        async def predict_popular(features: RestaurantFeatures):
            """Optimized popular prediction"""
            prediction_start = time.time()
            
            try:
                features_dict = features.dict()
                feature_array = self.prepare_features_optimized(features_dict)
                
                model = self.models['popular']
                probability = model.predict_proba(feature_array)[0, 1]
                prediction = int(probability >= 0.5)
                
                if probability >= 0.9:
                    confidence = "high"
                elif probability >= 0.7:
                    confidence = "medium"
                else:
                    confidence = "low"
                
                response_time = time.time() - prediction_start
                
                return PredictionResponse(
                    prediction_task="popular",
                    prediction=prediction,
                    probability=round(probability, 4),
                    confidence=confidence,
                    response_time=round(response_time, 4),
                    features_used=feature_array.shape[1]
                )
                
            except Exception as e:
                logger.error(f"Popular prediction error: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        
        @app.post("/predict/premium", response_model=PredictionResponse)
        async def predict_premium(features: RestaurantFeatures):
            """Optimized premium prediction"""
            prediction_start = time.time()
            
            try:
                features_dict = features.dict()
                feature_array = self.prepare_features_optimized(features_dict)
                
                model = self.models['premium']
                probability = model.predict_proba(feature_array)[0, 1]
                prediction = int(probability >= 0.5)
                
                if probability >= 0.8:
                    confidence = "high"
                elif probability >= 0.6:
                    confidence = "medium"
                else:
                    confidence = "low"
                
                response_time = time.time() - prediction_start
                
                return PredictionResponse(
                    prediction_task="premium",
                    prediction=prediction,
                    probability=round(probability, 4),
                    confidence=confidence,
                    response_time=round(response_time, 4),
                    features_used=feature_array.shape[1]
                )
                
            except Exception as e:
                logger.error(f"Premium prediction error: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        
        @app.get("/performance/metrics")
        async def get_performance_metrics():
            """Get performance metrics"""
            return {
                "optimizations": {
                    "feature_mapping": "pre_computed",
                    "model_warmup": "completed", 
                    "vector_operations": "optimized",
                    "data_types": "float32"
                },
                "expected_performance": {
                    "feature_preparation": "< 0.01s",
                    "prediction": "< 0.1s", 
                    "total_response": "< 0.2s"
                }
            }
        
        return app

def main():
    print("üöÄ Starting Optimized Phase 8: High-Performance FastAPI Deployment")
    print("=" * 70)
    
    try:
        setup_plotting()
        
        # Initialize optimized deployment manager
        manager = OptimizedDeploymentManager()
        
        # Load deployment models with optimization
        print("\nüì¶ Loading Optimized Deployment Models...")
        manager.load_deployment_models()
        
        # Create FastAPI app
        print("\nüîß Creating High-Performance FastAPI Application...")
        app = manager.create_fastapi_app()
        
        print("\n‚úÖ OPTIMIZED PHASE 8 COMPLETED SUCCESSFULLY!")
        print("=" * 70)
        print("üéØ Performance optimizations applied:")
        print("   ‚Ä¢ Model warm-up completed")
        print("   ‚Ä¢ Pre-computed feature mapping")
        print("   ‚Ä¢ Optimized vector operations")
        print("   ‚Ä¢ Response time monitoring")
        
        return app
        
    except Exception as e:
        logger.error(f"‚ùå Optimized Phase 8 failed: {e}")
        raise

# Create the optimized app instance for uvicorn
manager = OptimizedDeploymentManager()
manager.load_deployment_models()
app = manager.create_fastapi_app()

if __name__ == "__main__":
    main()